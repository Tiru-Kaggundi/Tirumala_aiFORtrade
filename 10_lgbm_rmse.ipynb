{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwKjVIMsLLcgEb0tETqolZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tiru-Kaggundi/Trade_AI/blob/main/10_lgbm_rmse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Title: 10_lgbm_rmse.ipynb\n",
        "Purpose: Train LightGBM (RMSE objective, log1p target) for direct h=2 forecasting.\n",
        "Data: features_train_h2.parquet (train ≤ 2025-08), features_test_h2.parquet (score 2025-10).\n",
        "Outputs:\n",
        "\t•\tOOF predictions → predictions/oof/lgbm_rmse_oof.parquet\n",
        "\t•\tForecast      → predictions/forecast/lgbm_rmse_forecast.parquet\n",
        "\t•\tCV scores     → logs/cv_scores.csv\n",
        "\t•\tRun metadata  → logs/runs/run_YYYYMMDD_HHMM.json"
      ],
      "metadata": {
        "id": "BkDUefWIrQt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "USE_DRIVE = True  # set False if running locally\n",
        "\n",
        "if USE_DRIVE:\n",
        "    from google.colab import drive  # noqa: F401\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/ai4trade\"\n",
        "\n",
        "DATA_DIR    = os.path.join(BASE_DIR, \"data\")\n",
        "FEATURE_DIR = os.path.join(DATA_DIR, \"features\")\n",
        "\n",
        "PRED_DIR  = os.path.join(BASE_DIR, \"predictions\")\n",
        "OOF_DIR   = os.path.join(PRED_DIR, \"oof\")\n",
        "FC_DIR    = os.path.join(PRED_DIR, \"forecast\")\n",
        "MERGED_DIR= os.path.join(PRED_DIR, \"merged\")\n",
        "\n",
        "LOG_DIR   = os.path.join(BASE_DIR, \"logs\")\n",
        "\n",
        "for d in [OOF_DIR, FC_DIR, MERGED_DIR, os.path.join(LOG_DIR, \"runs\")]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "RUN_ID = datetime.now().strftime(\"run_%Y%m%d_%H%M\")\n",
        "MODEL_NAME = \"lgbm_rmse\"\n",
        "\n",
        "print(\"BASE_DIR:\", BASE_DIR)\n",
        "print(\"RUN_ID  :\", RUN_ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKbBkCNv0vkS",
        "outputId": "0391c714-f2f3-4680-bbe6-dae287584a90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "BASE_DIR: /content/drive/MyDrive/ai4trade\n",
            "RUN_ID  : run_20251021_2333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install lightgbm==4.5.0 pyarrow==17.0.0\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from pathlib import Path\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 180)"
      ],
      "metadata": {
        "id": "N978G74Z0wdV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "def smape(y_true, y_pred, eps: float = 1.0):\n",
        "    \"\"\"Symmetric MAPE with epsilon floor.\"\"\"\n",
        "    y_true = np.asarray(y_true, dtype=float)\n",
        "    y_pred = np.asarray(y_pred, dtype=float)\n",
        "    denom = np.maximum(np.abs(y_true) + np.abs(y_pred), eps)\n",
        "    return np.mean(2.0 * np.abs(y_true - y_pred) / denom)\n",
        "\n",
        "# --- improved save_json with timestamp / numpy handling ---\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def _json_default(o):\n",
        "    if isinstance(o, (pd.Timestamp, )):\n",
        "        return o.isoformat()\n",
        "    if isinstance(o, (np.integer, )):\n",
        "        return int(o)\n",
        "    if isinstance(o, (np.floating, )):\n",
        "        return float(o)\n",
        "    if isinstance(o, (np.bool_, )):\n",
        "        return bool(o)\n",
        "    if isinstance(o, (np.ndarray, )):\n",
        "        return o.tolist()\n",
        "    try:\n",
        "        return str(o)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def save_json(obj, path: str):\n",
        "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(obj, f, indent=2, default=_json_default)\n",
        "\n",
        "def append_cv_score(log_path: str, row: Dict):\n",
        "    if os.path.exists(log_path):\n",
        "        df = pd.read_csv(log_path)\n",
        "        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "    else:\n",
        "        df = pd.DataFrame([row])\n",
        "    df.to_csv(log_path, index=False)"
      ],
      "metadata": {
        "id": "arriCEtD02Xt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = os.path.join(FEATURE_DIR, \"features_train_h2.parquet\")\n",
        "test_path  = os.path.join(FEATURE_DIR, \"features_test_h2.parquet\")\n",
        "\n",
        "df_train = pd.read_parquet(train_path)\n",
        "df_test  = pd.read_parquet(test_path)\n",
        "\n",
        "print(\"Train shape:\", df_train.shape)\n",
        "print(\"Test  shape:\", df_test.shape)\n",
        "\n",
        "# Expected core columns (train must include y_target; test may not)\n",
        "core_cols = {\"origin\", \"destination\", \"hs6\", \"hs4\", \"trade_flow\", \"month\", \"y\"}\n",
        "if not core_cols.issubset(df_train.columns):\n",
        "    missing = core_cols - set(df_train.columns)\n",
        "    raise ValueError(f\"Train missing core cols: {missing}\")\n",
        "if \"y_target\" not in df_train.columns:\n",
        "    raise ValueError(\"Train must include y_target for h=2.\")\n",
        "\n",
        "print(\"Train min/max month:\", df_train[\"month\"].min(), \"→\", df_train[\"month\"].max())\n",
        "print(\"Test  min/max month:\", df_test[\"month\"].min(),  \"→\", df_test[\"month\"].max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXxXwzW405zc",
        "outputId": "89d2eb79-cdff-47cc-f5fb-627c2f56b4ff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (5979239, 42)\n",
            "Test  shape: (320208, 42)\n",
            "Train min/max month: 2023-01-01 00:00:00 → 2024-08-01 00:00:00\n",
            "Test  min/max month: 2024-08-01 00:00:00 → 2024-08-01 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IDs and target settings\n",
        "id_cols    = [\"origin\", \"destination\", \"hs6\", \"hs4\", \"trade_flow\", \"month\"]\n",
        "id_cats    = [\"origin\", \"destination\", \"hs6\", \"hs4\", \"trade_flow\"]\n",
        "target_col = \"y_target\"\n",
        "\n",
        "# Keep rows with valid two-month-ahead targets\n",
        "df_train = df_train[df_train[target_col].notna()].copy()\n",
        "\n",
        "# Safety: clip negatives\n",
        "for c in [\"y\", target_col]:\n",
        "    if c in df_train:\n",
        "        df_train[c] = df_train[c].clip(lower=0)\n",
        "\n",
        "# Cast ID categoricals\n",
        "for c in id_cats:\n",
        "    if c in df_train: df_train[c] = df_train[c].astype(\"category\")\n",
        "    if c in df_test:  df_test[c]  = df_test[c].astype(\"category\")\n",
        "\n",
        "# Candidate features:\n",
        "# Keep *all* columns except: month (datetime), and y/y_target\n",
        "# NOTE: We DO include categorical IDs as features (helps GBMs).\n",
        "candidate_features = [c for c in df_train.columns if c not in {\"y\", target_col, \"month\"}]\n",
        "print(\"Initial candidate features (incl. categorical IDs):\", len(candidate_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s021W-Cd0-fh",
        "outputId": "d4c25cbc-f1af-402e-e168-4f03716fa5e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial candidate features (incl. categorical IDs): 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’ll inspect dtypes of all candidate features and then apply a single sanitization policy so LightGBM gets only numeric or categorical columns, with train/test aligned."
      ],
      "metadata": {
        "id": "YAuqAJVZ1ISy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "by_dtype = defaultdict(list)\n",
        "for c in candidate_features:\n",
        "    by_dtype[str(df_train[c].dtype)].append(c)\n",
        "\n",
        "print(\"=== DTYPE AUDIT (train) ===\")\n",
        "for dt, cols in sorted(by_dtype.items(), key=lambda kv: kv[0]):\n",
        "    head = \", \".join(cols[:12])\n",
        "    more = \" ...\" if len(cols) > 12 else \"\"\n",
        "    print(f\"{dt:>16} : {len(cols)} cols -> {head}{more}\")\n",
        "\n",
        "missing_in_test = sorted(set(candidate_features) - set(df_test.columns))\n",
        "if missing_in_test:\n",
        "    print(\"\\nWARNING: features missing in TEST (will drop):\", missing_in_test[:20], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PJuK1xo1EyR",
        "outputId": "d1093d01-be89-49b3-de15-365748e12257"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DTYPE AUDIT (train) ===\n",
            "        category : 5 cols -> origin, destination, hs6, hs4, trade_flow\n",
            "  datetime64[ns] : 1 cols -> cutoff_month\n",
            "         float32 : 21 cols -> lag_1, lag_2, lag_3, lag_6, lag_12, ma_3, ma_6, ma_12, roll_std_6, pctchg_1, pctchg_3, cross_flow_lag1 ...\n",
            "         float64 : 5 cols -> cf_ma3_import, cf_ma3_export, origin_total_exports, origin_total_imports, origin_total_trade\n",
            "           int16 : 1 cols -> consec_zero_run\n",
            "           int32 : 1 cols -> month_id\n",
            "           int64 : 1 cols -> value\n",
            "            int8 : 4 cols -> month_num, quarter, was_trade_lag1, horizon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas.api.types as pdt\n",
        "\n",
        "OBJ_TO_NUMERIC_THRESHOLD = 0.97  # try convert object→numeric if ≥97% convertible\n",
        "\n",
        "# --- Robust dtype testers (work fine with CategoricalDtype) ---\n",
        "def is_datetime_dtype(s: pd.Series) -> bool:\n",
        "    return pdt.is_datetime64_any_dtype(s)\n",
        "\n",
        "def is_period_dtype(s: pd.Series) -> bool:\n",
        "    return pdt.is_period_dtype(s)\n",
        "\n",
        "def is_timedelta_dtype(s: pd.Series) -> bool:\n",
        "    return pdt.is_timedelta64_dtype(s)\n",
        "\n",
        "def is_sparse_dtype(s: pd.Series) -> bool:\n",
        "    return pdt.is_sparse(s.dtype)\n",
        "\n",
        "def is_category_dtype(s: pd.Series) -> bool:\n",
        "    return pdt.is_categorical_dtype(s)\n",
        "\n",
        "def is_numeric_or_bool(s: pd.Series) -> bool:\n",
        "    return pdt.is_integer_dtype(s) or pdt.is_float_dtype(s) or pdt.is_bool_dtype(s)\n",
        "\n",
        "def try_object_to_numeric(series: pd.Series):\n",
        "    conv = pd.to_numeric(series, errors=\"coerce\")\n",
        "    ok_ratio = conv.notna().mean()\n",
        "    return ok_ratio >= OBJ_TO_NUMERIC_THRESHOLD, conv\n",
        "\n",
        "# --- Build plan on TRAIN ---\n",
        "plan = {}  # col -> action\n",
        "for c in candidate_features:\n",
        "    s = df_train[c]\n",
        "\n",
        "    if is_datetime_dtype(s) or is_period_dtype(s) or is_timedelta_dtype(s):\n",
        "        plan[c] = \"drop_dt\"\n",
        "    elif is_sparse_dtype(s):\n",
        "        plan[c] = \"sparse_to_dense\"\n",
        "    elif is_category_dtype(s):\n",
        "        plan[c] = \"keep_category\"\n",
        "    elif is_numeric_or_bool(s):\n",
        "        if pdt.is_bool_dtype(s):\n",
        "            plan[c] = \"bool_to_int8\"\n",
        "        elif pdt.is_float_dtype(s):\n",
        "            plan[c] = \"float_to_float32\"\n",
        "        else:\n",
        "            plan[c] = \"int_to_int32\"\n",
        "    elif pdt.is_object_dtype(s):\n",
        "        ok, _ = try_object_to_numeric(s)\n",
        "        plan[c] = \"object_to_numeric\" if ok else \"drop_object\"\n",
        "    else:\n",
        "        plan[c] = \"drop_unknown\"\n",
        "\n",
        "# --- Apply plan to TRAIN & TEST ---\n",
        "def apply_plan(df: pd.DataFrame, plan: dict) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    drops = []\n",
        "    for c, action in plan.items():\n",
        "        if c not in out.columns:\n",
        "            continue\n",
        "        s = out[c]\n",
        "        if action in (\"drop_dt\", \"drop_object\", \"drop_unknown\"):\n",
        "            drops.append(c)\n",
        "        elif action == \"sparse_to_dense\":\n",
        "            out[c] = pd.Series(pd.arrays.SparseArray(s).to_dense(), index=s.index)\n",
        "        elif action == \"keep_category\":\n",
        "            out[c] = out[c].astype(\"category\")\n",
        "        elif action == \"bool_to_int8\":\n",
        "            out[c] = out[c].astype(\"int8\")\n",
        "        elif action == \"float_to_float32\":\n",
        "            out[c] = out[c].astype(\"float32\")\n",
        "        elif action == \"int_to_int32\":\n",
        "            out[c] = out[c].astype(\"int32\")\n",
        "        elif action == \"object_to_numeric\":\n",
        "            out[c] = pd.to_numeric(out[c], errors=\"coerce\").astype(\"float32\")\n",
        "    if drops:\n",
        "        out = out.drop(columns=[c for c in drops if c in out.columns])\n",
        "    return out\n",
        "\n",
        "df_train_s = apply_plan(df_train, plan)\n",
        "df_test_s  = apply_plan(df_test,  plan)\n",
        "\n",
        "# Common, model-usable features\n",
        "common_feats = sorted((set(df_train_s.columns) & set(df_test_s.columns)) - {\"y\", target_col, \"month\"})\n",
        "feature_cols = []\n",
        "for c in common_feats:\n",
        "    s = df_train_s[c]\n",
        "    if pdt.is_integer_dtype(s) or pdt.is_float_dtype(s) or pdt.is_categorical_dtype(s):\n",
        "        feature_cols.append(c)\n",
        "\n",
        "print(f\"Kept {len(feature_cols)} features after sanitization.\")\n",
        "print(\"Sample:\", feature_cols[:20])\n",
        "\n",
        "# Final safety\n",
        "bad_now = [c for c in feature_cols if (pdt.is_object_dtype(df_train_s[c]) or pdt.is_datetime64_any_dtype(df_train_s[c]))]\n",
        "assert not bad_now, f\"Unexpected dtypes remain: {bad_now}\"\n",
        "\n",
        "# Replace downstream dataframes\n",
        "df_train = df_train_s\n",
        "df_test  = df_test_s\n",
        "\n",
        "print(\"\\nTrain dtypes (features):\")\n",
        "print(df_train[feature_cols].dtypes.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gktafSnn1OhD",
        "outputId": "ed129e7c-c570-441f-f41c-3c25f0a9b1e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3783575781.py:12: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
            "  return pdt.is_period_dtype(s)\n",
            "/tmp/ipython-input-3783575781.py:18: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  return pdt.is_sparse(s.dtype)\n",
            "/tmp/ipython-input-3783575781.py:21: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  return pdt.is_categorical_dtype(s)\n",
            "/tmp/ipython-input-3783575781.py:89: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pdt.is_integer_dtype(s) or pdt.is_float_dtype(s) or pdt.is_categorical_dtype(s):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kept 38 features after sanitization.\n",
            "Sample: ['cf_ma3_export', 'cf_ma3_import', 'consec_zero_run', 'cross_flow_lag1', 'cross_flow_lag10', 'cross_flow_ma3', 'destination', 'horizon', 'hs4', 'hs6', 'lag_1', 'lag_12', 'lag_2', 'lag_3', 'lag_6', 'ma_12', 'ma_3', 'ma_6', 'month_id', 'month_num']\n",
            "\n",
            "Train dtypes (features):\n",
            "float32     26\n",
            "int32        7\n",
            "category     1\n",
            "category     1\n",
            "category     1\n",
            "category     1\n",
            "category     1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation mirrors h=2 setup (target months are 2023-09, 2024-03, 2024-09).\n",
        "For each fold: train on rows with month ≤ train_end, validate on rows where month = val_target − 2 months."
      ],
      "metadata": {
        "id": "7c3dIag-1wsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ts(ym: str) -> pd.Timestamp:\n",
        "    return pd.to_datetime(ym + \"-01\")\n",
        "\n",
        "folds = [\n",
        "    {\"fold\": \"F1\", \"train_end\": ts(\"2023-07\"), \"val_target\": ts(\"2023-09\")},\n",
        "    {\"fold\": \"F2\", \"train_end\": ts(\"2024-01\"), \"val_target\": ts(\"2024-03\")},\n",
        "    {\"fold\": \"F3\", \"train_end\": ts(\"2024-07\"), \"val_target\": ts(\"2024-09\")},\n",
        "]\n",
        "folds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lIAUzNl1qVA",
        "outputId": "a1a452fc-4c9d-4e35-dd84-6c51731be005"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'fold': 'F1',\n",
              "  'train_end': Timestamp('2023-07-01 00:00:00'),\n",
              "  'val_target': Timestamp('2023-09-01 00:00:00')},\n",
              " {'fold': 'F2',\n",
              "  'train_end': Timestamp('2024-01-01 00:00:00'),\n",
              "  'val_target': Timestamp('2024-03-01 00:00:00')},\n",
              " {'fold': 'F3',\n",
              "  'train_end': Timestamp('2024-07-01 00:00:00'),\n",
              "  'val_target': Timestamp('2024-09-01 00:00:00')}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 2025\n",
        "\n",
        "lgb_params = {\n",
        "    \"objective\": \"rmse\",   # RMSE on log1p(y)\n",
        "    \"metric\": \"rmse\",\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"num_leaves\": 64,\n",
        "    \"min_data_in_leaf\": 100,\n",
        "    \"feature_fraction\": 0.8,\n",
        "    \"bagging_fraction\": 0.8,\n",
        "    \"bagging_freq\": 1,\n",
        "    \"lambda_l2\": 2.0,\n",
        "    \"max_depth\": -1,\n",
        "    \"verbosity\": -1,\n",
        "    \"force_row_wise\": True,\n",
        "    \"seed\": SEED,\n",
        "}\n",
        "\n",
        "# Categorical features = any of the feature_cols that are categorical dtypes\n",
        "cat_cols = [c for c in feature_cols if pd.api.types.is_categorical_dtype(df_train[c])]\n",
        "\n",
        "def fit_one_fold(train_df, val_df, features, cat_cols, params,\n",
        "                 early_stopping_rounds=200, num_boost_round=5000, verbose_eval=200):\n",
        "    y_tr = np.log1p(train_df[\"y_target\"].values)\n",
        "    y_va = np.log1p(val_df[\"y_target\"].values)\n",
        "\n",
        "    dtrain = lgb.Dataset(train_df[features], label=y_tr,\n",
        "                         categorical_feature=cat_cols, free_raw_data=False)\n",
        "    dvalid = lgb.Dataset(val_df[features], label=y_va,\n",
        "                         categorical_feature=cat_cols, reference=dtrain, free_raw_data=False)\n",
        "\n",
        "    callbacks = [\n",
        "        lgb.early_stopping(stopping_rounds=early_stopping_rounds, verbose=True),\n",
        "        lgb.log_evaluation(period=verbose_eval),\n",
        "    ]\n",
        "\n",
        "    model = lgb.train(\n",
        "        params=params,\n",
        "        train_set=dtrain,\n",
        "        valid_sets=[dtrain, dvalid],\n",
        "        valid_names=[\"train\", \"valid\"],\n",
        "        num_boost_round=num_boost_round,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "    return model, model.best_iteration"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5okgFSAc10ko",
        "outputId": "5330b4df-ee0b-4335-e0df-003cda0d963a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2188999997.py:20: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  cat_cols = [c for c in feature_cols if pd.api.types.is_categorical_dtype(df_train[c])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oof_rows = []\n",
        "cv_logs  = []\n",
        "\n",
        "for f in folds:\n",
        "    fold_name  = f[\"fold\"]\n",
        "    train_end  = f[\"train_end\"]\n",
        "    val_target = f[\"val_target\"]\n",
        "\n",
        "    # Train: month ≤ train_end\n",
        "    trn_mask = df_train[\"month\"] <= train_end\n",
        "\n",
        "    # Valid: feature month = val_target - 2 months\n",
        "    val_month = (val_target - pd.DateOffset(months=2)).replace(day=1)\n",
        "    va_mask = df_train[\"month\"] == val_month\n",
        "\n",
        "    trn_df = df_train.loc[trn_mask].copy()\n",
        "    va_df  = df_train.loc[va_mask].copy()\n",
        "\n",
        "    print(f\"\\n=== {fold_name} | train_end={train_end.date()} | val_target={val_target.date()} ===\")\n",
        "    print(\"Train rows:\", len(trn_df), \" Valid rows:\", len(va_df))\n",
        "    if len(va_df) == 0:\n",
        "        print(\"WARNING: No validation rows for this fold — skipping.\")\n",
        "        continue\n",
        "\n",
        "    model, best_iter = fit_one_fold(\n",
        "        trn_df, va_df,\n",
        "        feature_cols, cat_cols, lgb_params,\n",
        "        early_stopping_rounds=200, num_boost_round=5000, verbose_eval=200\n",
        "    )\n",
        "\n",
        "    va_pred = model.predict(va_df[feature_cols], num_iteration=best_iter)\n",
        "    va_pred = np.expm1(va_pred)\n",
        "    va_pred = np.clip(va_pred, 0.0, None)\n",
        "\n",
        "    fold_smape = smape(va_df[\"y_target\"].values, va_pred, eps=1.0)\n",
        "    print(f\"{fold_name} sMAPE:\", round(fold_smape, 4))\n",
        "\n",
        "    tmp = va_df[[\"origin\", \"destination\", \"hs6\", \"hs4\", \"trade_flow\", \"month\"]].copy()\n",
        "    tmp[\"y_true\"] = va_df[\"y_target\"].values\n",
        "    tmp[\"y_pred_\" + MODEL_NAME] = va_pred\n",
        "    tmp[\"fold\"] = fold_name\n",
        "    oof_rows.append(tmp)\n",
        "\n",
        "    cv_logs.append({\n",
        "        \"run_id\": RUN_ID,\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"fold\": fold_name,\n",
        "        \"train_end\": str(train_end.date()),\n",
        "        \"val_target\": str(val_target.date()),\n",
        "        \"rows_train\": len(trn_df),\n",
        "        \"rows_valid\": len(va_df),\n",
        "        \"smape\": fold_smape\n",
        "    })\n",
        "\n",
        "if len(oof_rows):\n",
        "    oof_df = pd.concat(oof_rows, ignore_index=True)\n",
        "    overall_smape = smape(oof_df[\"y_true\"].values, oof_df[\"y_pred_\" + MODEL_NAME].values, eps=1.0)\n",
        "    print(\"\\n=== OOF Overall sMAPE:\", round(overall_smape, 4), \"===\")\n",
        "\n",
        "    oof_path = os.path.join(OOF_DIR, f\"{MODEL_NAME}_oof.parquet\")\n",
        "    oof_df.to_parquet(oof_path, index=False)\n",
        "    print(\"Saved OOF to:\", oof_path)\n",
        "\n",
        "    for row in cv_logs:\n",
        "        append_cv_score(os.path.join(LOG_DIR, \"cv_scores.csv\"), row)\n",
        "\n",
        "    append_cv_score(os.path.join(LOG_DIR, \"cv_scores.csv\"), {\n",
        "        \"run_id\": RUN_ID, \"model\": MODEL_NAME, \"fold\": \"OOF\",\n",
        "        \"train_end\": \"\", \"val_target\": \"\",\n",
        "        \"rows_train\": int(df_train.shape[0]), \"rows_valid\": int(oof_df.shape[0]),\n",
        "        \"smape\": overall_smape\n",
        "    })\n",
        "else:\n",
        "    print(\"No OOF rows collected — check fold date logic or coverage.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD-iCk3f132k",
        "outputId": "b730d73f-47e7-4926-e645-f859609ba29f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== F1 | train_end=2023-07-01 | val_target=2023-09-01 ===\n",
            "Train rows: 2047602  Valid rows: 316445\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttrain's rmse: 2.68629\tvalid's rmse: 2.66956\n",
            "[400]\ttrain's rmse: 2.63627\tvalid's rmse: 2.60291\n",
            "[600]\ttrain's rmse: 2.60878\tvalid's rmse: 2.57342\n",
            "[800]\ttrain's rmse: 2.58937\tvalid's rmse: 2.55374\n",
            "[1000]\ttrain's rmse: 2.57494\tvalid's rmse: 2.53895\n",
            "[1200]\ttrain's rmse: 2.56178\tvalid's rmse: 2.52505\n",
            "[1400]\ttrain's rmse: 2.5496\tvalid's rmse: 2.51355\n",
            "[1600]\ttrain's rmse: 2.53914\tvalid's rmse: 2.50289\n",
            "[1800]\ttrain's rmse: 2.52866\tvalid's rmse: 2.492\n",
            "[2000]\ttrain's rmse: 2.51961\tvalid's rmse: 2.48285\n",
            "[2200]\ttrain's rmse: 2.51076\tvalid's rmse: 2.47304\n",
            "[2400]\ttrain's rmse: 2.50273\tvalid's rmse: 2.46479\n",
            "[2600]\ttrain's rmse: 2.49448\tvalid's rmse: 2.45547\n",
            "[2800]\ttrain's rmse: 2.48652\tvalid's rmse: 2.44702\n",
            "[3000]\ttrain's rmse: 2.4784\tvalid's rmse: 2.43831\n",
            "[3200]\ttrain's rmse: 2.47082\tvalid's rmse: 2.4303\n",
            "[3400]\ttrain's rmse: 2.46309\tvalid's rmse: 2.42193\n",
            "[3600]\ttrain's rmse: 2.45615\tvalid's rmse: 2.41409\n",
            "[3800]\ttrain's rmse: 2.44908\tvalid's rmse: 2.40661\n",
            "[4000]\ttrain's rmse: 2.44234\tvalid's rmse: 2.39947\n",
            "[4200]\ttrain's rmse: 2.43573\tvalid's rmse: 2.39192\n",
            "[4400]\ttrain's rmse: 2.42935\tvalid's rmse: 2.38435\n",
            "[4600]\ttrain's rmse: 2.42296\tvalid's rmse: 2.37754\n",
            "[4800]\ttrain's rmse: 2.41694\tvalid's rmse: 2.37163\n",
            "[5000]\ttrain's rmse: 2.41095\tvalid's rmse: 2.3648\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttrain's rmse: 2.41095\tvalid's rmse: 2.3648\n",
            "F1 sMAPE: 0.982\n",
            "\n",
            "=== F2 | train_end=2024-01-01 | val_target=2024-03-01 ===\n",
            "Train rows: 3893891  Valid rows: 253011\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttrain's rmse: 2.61648\tvalid's rmse: 2.23418\n",
            "[400]\ttrain's rmse: 2.57657\tvalid's rmse: 2.18887\n",
            "[600]\ttrain's rmse: 2.55512\tvalid's rmse: 2.1577\n",
            "[800]\ttrain's rmse: 2.54209\tvalid's rmse: 2.14151\n",
            "[1000]\ttrain's rmse: 2.53199\tvalid's rmse: 2.13048\n",
            "[1200]\ttrain's rmse: 2.5229\tvalid's rmse: 2.12191\n",
            "[1400]\ttrain's rmse: 2.5153\tvalid's rmse: 2.11266\n",
            "[1600]\ttrain's rmse: 2.50785\tvalid's rmse: 2.10483\n",
            "[1800]\ttrain's rmse: 2.50098\tvalid's rmse: 2.09871\n",
            "[2000]\ttrain's rmse: 2.49481\tvalid's rmse: 2.09352\n",
            "[2200]\ttrain's rmse: 2.48861\tvalid's rmse: 2.08791\n",
            "[2400]\ttrain's rmse: 2.48314\tvalid's rmse: 2.08315\n",
            "[2600]\ttrain's rmse: 2.47768\tvalid's rmse: 2.07851\n",
            "[2800]\ttrain's rmse: 2.47228\tvalid's rmse: 2.07386\n",
            "[3000]\ttrain's rmse: 2.46723\tvalid's rmse: 2.06907\n",
            "[3200]\ttrain's rmse: 2.46196\tvalid's rmse: 2.06455\n",
            "[3400]\ttrain's rmse: 2.45724\tvalid's rmse: 2.06033\n",
            "[3600]\ttrain's rmse: 2.45237\tvalid's rmse: 2.05634\n",
            "[3800]\ttrain's rmse: 2.44759\tvalid's rmse: 2.05212\n",
            "[4000]\ttrain's rmse: 2.44292\tvalid's rmse: 2.04847\n",
            "[4200]\ttrain's rmse: 2.43828\tvalid's rmse: 2.04326\n",
            "[4400]\ttrain's rmse: 2.43364\tvalid's rmse: 2.03928\n",
            "[4600]\ttrain's rmse: 2.42891\tvalid's rmse: 2.03563\n",
            "[4800]\ttrain's rmse: 2.42462\tvalid's rmse: 2.03191\n",
            "[5000]\ttrain's rmse: 2.42057\tvalid's rmse: 2.02839\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttrain's rmse: 2.42057\tvalid's rmse: 2.02839\n",
            "F2 sMAPE: 0.7994\n",
            "\n",
            "=== F3 | train_end=2024-07-01 | val_target=2024-09-01 ===\n",
            "Train rows: 5664725  Valid rows: 311662\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttrain's rmse: 2.62445\tvalid's rmse: 2.66556\n",
            "[400]\ttrain's rmse: 2.58647\tvalid's rmse: 2.61097\n",
            "[600]\ttrain's rmse: 2.56753\tvalid's rmse: 2.58726\n",
            "[800]\ttrain's rmse: 2.55467\tvalid's rmse: 2.57403\n",
            "[1000]\ttrain's rmse: 2.54414\tvalid's rmse: 2.5628\n",
            "[1200]\ttrain's rmse: 2.53563\tvalid's rmse: 2.55309\n",
            "[1400]\ttrain's rmse: 2.52813\tvalid's rmse: 2.54507\n",
            "[1600]\ttrain's rmse: 2.52127\tvalid's rmse: 2.53769\n",
            "[1800]\ttrain's rmse: 2.51525\tvalid's rmse: 2.53139\n",
            "[2000]\ttrain's rmse: 2.50968\tvalid's rmse: 2.52564\n",
            "[2200]\ttrain's rmse: 2.50444\tvalid's rmse: 2.5201\n",
            "[2400]\ttrain's rmse: 2.4995\tvalid's rmse: 2.51523\n",
            "[2600]\ttrain's rmse: 2.49493\tvalid's rmse: 2.5105\n",
            "[2800]\ttrain's rmse: 2.49059\tvalid's rmse: 2.50622\n",
            "[3000]\ttrain's rmse: 2.48614\tvalid's rmse: 2.50184\n",
            "[3200]\ttrain's rmse: 2.48188\tvalid's rmse: 2.49737\n",
            "[3400]\ttrain's rmse: 2.47776\tvalid's rmse: 2.49337\n",
            "[3600]\ttrain's rmse: 2.47364\tvalid's rmse: 2.48903\n",
            "[3800]\ttrain's rmse: 2.46983\tvalid's rmse: 2.48518\n",
            "[4000]\ttrain's rmse: 2.46596\tvalid's rmse: 2.4813\n",
            "[4200]\ttrain's rmse: 2.46228\tvalid's rmse: 2.47767\n",
            "[4400]\ttrain's rmse: 2.45847\tvalid's rmse: 2.47364\n",
            "[4600]\ttrain's rmse: 2.45485\tvalid's rmse: 2.46964\n",
            "[4800]\ttrain's rmse: 2.4512\tvalid's rmse: 2.46556\n",
            "[5000]\ttrain's rmse: 2.44794\tvalid's rmse: 2.46217\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttrain's rmse: 2.44794\tvalid's rmse: 2.46217\n",
            "F3 sMAPE: 0.9816\n",
            "\n",
            "=== OOF Overall sMAPE: 0.9294 ===\n",
            "Saved OOF to: /content/drive/MyDrive/ai4trade/predictions/oof/lgbm_rmse_oof.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train on full train set\n",
        "full_train = df_train.copy()\n",
        "y_full = np.log1p(full_train[\"y_target\"].values)\n",
        "dtrain_full = lgb.Dataset(full_train[feature_cols], label=y_full,\n",
        "                          categorical_feature=cat_cols, free_raw_data=False)\n",
        "\n",
        "# Use a conservative round cap; adjust later based on CV\n",
        "final_params = lgb_params.copy()\n",
        "final_num_boost_round = 2500\n",
        "\n",
        "final_model = lgb.train(\n",
        "    params=final_params,\n",
        "    train_set=dtrain_full,\n",
        "    num_boost_round=final_num_boost_round,\n",
        "    valid_sets=[dtrain_full],\n",
        "    valid_names=[\"train\"],\n",
        "    callbacks=[lgb.log_evaluation(period=500)]\n",
        ")\n",
        "\n",
        "# Forecast for test_h2 (these rows map to target = 2025-10)\n",
        "test_pred = final_model.predict(df_test[feature_cols], num_iteration=final_model.best_iteration or final_num_boost_round)\n",
        "test_pred = np.expm1(test_pred)\n",
        "test_pred = np.clip(test_pred, 0.0, None)\n",
        "\n",
        "fc_df = df_test[[\"origin\", \"destination\", \"hs6\", \"hs4\", \"trade_flow\", \"month\"]].copy()\n",
        "fc_df[\"y_pred_\" + MODEL_NAME] = test_pred\n",
        "\n",
        "fc_path = os.path.join(FC_DIR, f\"{MODEL_NAME}_forecast.parquet\")\n",
        "fc_df.to_parquet(fc_path, index=False)\n",
        "print(\"Saved forecast to:\", fc_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH46H1qa2JHL",
        "outputId": "4232993d-96cf-443e-84a1-b08e95924ca2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[500]\ttrain's rmse: 2.57944\n",
            "[1000]\ttrain's rmse: 2.54759\n",
            "[1500]\ttrain's rmse: 2.52877\n",
            "[2000]\ttrain's rmse: 2.51456\n",
            "[2500]\ttrain's rmse: 2.50252\n",
            "Saved forecast to: /content/drive/MyDrive/ai4trade/predictions/forecast/lgbm_rmse_forecast.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to pull OOF overall sMAPE if available\n",
        "try:\n",
        "    overall_smape\n",
        "except NameError:\n",
        "    overall_smape = None\n",
        "\n",
        "run_meta = {\n",
        "    \"run_id\": RUN_ID,\n",
        "    \"model\": MODEL_NAME,\n",
        "    \"time\": datetime.now().isoformat(),\n",
        "    \"params\": lgb_params,\n",
        "    \"feature_count\": len(feature_cols),\n",
        "    \"categorical_features\": cat_cols,\n",
        "    \"folds\": folds,\n",
        "    \"oof_smape\": float(overall_smape) if overall_smape is not None else None,\n",
        "    \"train_path\": train_path,\n",
        "    \"test_path\": test_path,\n",
        "    \"oof_output\": os.path.join(OOF_DIR, f\"{MODEL_NAME}_oof.parquet\"),\n",
        "    \"forecast_output\": os.path.join(FC_DIR, f\"{MODEL_NAME}_forecast.parquet\"),\n",
        "}\n",
        "meta_path = os.path.join(LOG_DIR, \"runs\", f\"{RUN_ID}.json\")\n",
        "save_json(run_meta, meta_path)\n",
        "print(\"Saved metadata to:\", meta_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqaMkRbP2O10",
        "outputId": "09ae5f87-9cf3-4869-d9f2-74193262082b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved metadata to: /content/drive/MyDrive/ai4trade/logs/runs/run_20251021_2333.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we now have:\n",
        "\t•\tOOF: predictions/oof/lgbm_rmse_oof.parquet\n",
        "\t•\tForecast: predictions/forecast/lgbm_rmse_forecast.parquet\n",
        "\t•\tLogs: logs/cv_scores.csv, logs/runs/{RUN_ID}.json\n",
        "\n",
        "Next steps:\n",
        "\t1.\tRun 11_lgbm_tweedie.ipynb (same folds; objective='tweedie', sweep tweedie_variance_power∈[1.2,1.5]).\n",
        "\t2.\tTrain xgb_tweedie, catboost_log1p, stl_ets, seasonal_naive, (optional) nHiTS.\n",
        "\t3.\tBlend in 40_blend_weights.ipynb (non-negative weights minimizing sMAPE).\n",
        "\t4.\tAggregate HS-6→HS-4 and export submission CSV in 50_make_submission.ipynb."
      ],
      "metadata": {
        "id": "8o6VyBIS2S8p"
      }
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNCc1bbImWkKYHUdNFeESYw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tiru-Kaggundi/Trade_AI/blob/main/XGBoost_tweedie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-AaGoA0-NO-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a54bc6f-05af-4f78-816a-91b516915b7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q show xgboost\n",
        "\n",
        "import os, json, gc, numpy as np, pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/ai4trade\"\n",
        "FEAT_DIR = f\"{BASE_DIR}/data/features\"\n",
        "OOF_DIR  = f\"{BASE_DIR}/predictions/oof\"\n",
        "FCST_DIR = f\"{BASE_DIR}/predictions/forecast\"\n",
        "LOG_DIR  = f\"{BASE_DIR}/logs/runs\"\n",
        "MODEL_DIR= f\"{BASE_DIR}/models/xgb_tweedie\"\n",
        "\n",
        "for d in (OOF_DIR, FCST_DIR, LOG_DIR, MODEL_DIR):\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "RUN_ID = datetime.now().strftime(\"xgb_tweedie_h2_%Y%m%d_%H%M\")\n",
        "print(\"RUN:\", RUN_ID)\n"
      ],
      "metadata": {
        "id": "IvcbZmmRObph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7104a9d9-e8d1-4e24-fec7-017836f020dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUN: xgb_tweedie_h2_20251024_1438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_parquet(f\"{FEAT_DIR}/features_train_h2.parquet\")\n",
        "test  = pd.read_parquet(f\"{FEAT_DIR}/features_test_h2.parquet\")\n",
        "\n",
        "ID_COLS = [\"origin\",\"destination\",\"hs6\",\"trade_flow\",\"month\"]\n",
        "TARGET  = \"y_target\"   # already shifted to t+2 in your feature pipeline\n",
        "\n",
        "drop_cols = set(ID_COLS + [TARGET])\n",
        "FEATS = [c for c in train.columns\n",
        "         if c not in drop_cols and np.issubdtype(train[c].dtype, np.number)]\n",
        "\n",
        "# Fill NaNs and drop constant columns for speed\n",
        "for c in FEATS:\n",
        "    if train[c].isna().any(): train[c] = train[c].fillna(0.0)\n",
        "    if test[c].isna().any():  test[c]  = test[c].fillna(0.0)\n",
        "\n",
        "nunq = train[FEATS].nunique()\n",
        "FEATS = [c for c in FEATS if nunq[c] > 1]\n",
        "\n",
        "# Cast to float32 (big speed + memory win)\n",
        "train[FEATS] = train[FEATS].astype(np.float32)\n",
        "test[FEATS]  = test[FEATS].astype(np.float32)\n",
        "\n",
        "# Build series key for grouped CV\n",
        "train[\"series_key\"] = (\n",
        "    train[\"origin\"]+\"|\"+train[\"destination\"]+\"|\"+train[\"hs6\"]+\"|\"+train[\"trade_flow\"]\n",
        ")\n",
        "\n",
        "gkf = GroupKFold(n_splits=3)\n",
        "folds = [(tr, va) for tr, va in gkf.split(train[FEATS], groups=train[\"series_key\"])]\n",
        "len(FEATS), len(train), len(test)\n"
      ],
      "metadata": {
        "id": "ZGmobVzzOi1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347c43b6-7b85-47ba-a0e4-fc45191b8021"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33, 5979239, 320208)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smape(y_true, y_pred, eps=1.0):\n",
        "    y_true = np.asarray(y_true, float)\n",
        "    y_pred = np.asarray(y_pred, float).clip(min=0)\n",
        "    denom = np.maximum(np.abs(y_true)+np.abs(y_pred), eps)\n",
        "    return float(np.mean(2.0*np.abs(y_true - y_pred)/denom))\n"
      ],
      "metadata": {
        "id": "ucONtfD3Ol6I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cpu\"\n",
        "try:\n",
        "    _probe = XGBRegressor(tree_method=\"hist\", device=\"cuda\")\n",
        "    _ = _probe.get_xgb_params()\n",
        "    DEVICE = \"cuda\"\n",
        "except Exception:\n",
        "    pass\n",
        "print(\"Using device:\", DEVICE)\n"
      ],
      "metadata": {
        "id": "IuR0IvNLOsEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27743393-ec23-4800-9243-254b6057b280"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_params = dict(\n",
        "    n_estimators=1500,       # early stopping active → stops earlier\n",
        "    learning_rate=0.05,\n",
        "    max_depth=7,\n",
        "    min_child_weight=4,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_alpha=0.0,\n",
        "    reg_lambda=2.0,\n",
        "    n_jobs=-1,\n",
        "    tree_method=\"hist\",\n",
        "    objective=\"reg:tweedie\",\n",
        "    eval_metric=\"rmse\",\n",
        "    max_bin=128,\n",
        "    early_stopping_rounds=100,   # <— moved ES here\n",
        ")\n",
        "if DEVICE == \"cuda\":\n",
        "    base_params[\"device\"] = \"cuda\"\n",
        "\n",
        "POWER_GRID = [1.20, 1.35, 1.50]   # recommended sweep\n"
      ],
      "metadata": {
        "id": "xXRDWlCmOs6w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 — Train CV across powers, collect OOF (robust to missing best_iteration)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def _predict_best(model, X):\n",
        "    \"\"\"Use best_iteration if early stopping set it; else use full model.\"\"\"\n",
        "    bi = getattr(model, \"best_iteration\", None)\n",
        "    if isinstance(bi, (int, np.integer)) and bi >= 0:\n",
        "        return model.predict(X, iteration_range=(0, bi + 1))\n",
        "    return model.predict(X)\n",
        "\n",
        "results = []\n",
        "oof_by_power = {}\n",
        "\n",
        "# Pre-allocate once for speed; we overwrite per power\n",
        "oof = np.zeros(len(train), dtype=np.float32)\n",
        "\n",
        "for p in POWER_GRID:\n",
        "    params = {**base_params, \"tweedie_variance_power\": p}\n",
        "    print(f\"\\n=== Training Tweedie power={p} ===\")\n",
        "    fold_scores = []\n",
        "    oof[:] = 0.0  # reset buffer\n",
        "\n",
        "    for k, (tr_idx, va_idx) in enumerate(folds, 1):\n",
        "        tr, va = train.iloc[tr_idx], train.iloc[va_idx]\n",
        "\n",
        "        model = XGBRegressor(**params)\n",
        "        model.fit(\n",
        "            tr[FEATS], tr[TARGET],\n",
        "            eval_set=[(va[FEATS], va[TARGET])],\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        pred = _predict_best(model, va[FEATS]).clip(min=0)\n",
        "        score = smape(va[TARGET].values, pred)\n",
        "        oof[va_idx] = pred.astype(np.float32)\n",
        "\n",
        "        print(f\"  Fold {k} sMAPE: {score:.4f}\")\n",
        "        fold_scores.append(score)\n",
        "\n",
        "    cv = float(np.mean(fold_scores))\n",
        "    print(f\"  -> CV sMAPE (p={p}): {cv:.4f}\")\n",
        "\n",
        "    # keep per-power OOF and a canonical column on train for inspection\n",
        "    train[f\"y_pred_xgb_tweedie_p{p}\"] = oof\n",
        "    oof_by_power[p] = oof.copy()\n",
        "    results.append({\"power\": p, \"cv_smape\": cv, \"fold_smape\": fold_scores})\n",
        "\n",
        "# Select best power & finalize canonical OOF column\n",
        "best = min(results, key=lambda d: d[\"cv_smape\"])\n",
        "best_power = best[\"power\"]\n",
        "train[\"y_pred_xgb_tweedie\"] = train[f\"y_pred_xgb_tweedie_p{best_power}\"].astype(np.float32)\n",
        "cv_smape = smape(train[TARGET], train[\"y_pred_xgb_tweedie\"])\n",
        "print(\"\\nBest Tweedie power:\", best_power, \"CV sMAPE:\", round(best[\"cv_smape\"], 4))\n",
        "print(\"OOF sMAPE (best power):\", round(cv_smape, 4))"
      ],
      "metadata": {
        "id": "Dfz6EIBLOutf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bfaf5ff-6c6a-459c-f106-5c15c27dfdb1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training Tweedie power=1.2 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:774: UserWarning: [14:48:16] WARNING: /workspace/src/common/error_msg.cc:41: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  return func(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Fold 1 sMAPE: 0.9066\n",
            "  Fold 2 sMAPE: 0.9060\n",
            "  Fold 3 sMAPE: 0.9064\n",
            "  -> CV sMAPE (p=1.2): 0.9063\n",
            "\n",
            "=== Training Tweedie power=1.35 ===\n",
            "  Fold 1 sMAPE: 0.9035\n",
            "  Fold 2 sMAPE: 0.9035\n",
            "  Fold 3 sMAPE: 0.9031\n",
            "  -> CV sMAPE (p=1.35): 0.9034\n",
            "\n",
            "=== Training Tweedie power=1.5 ===\n",
            "  Fold 1 sMAPE: 0.9009\n",
            "  Fold 2 sMAPE: 0.9011\n",
            "  Fold 3 sMAPE: 0.9005\n",
            "  -> CV sMAPE (p=1.5): 0.9008\n",
            "\n",
            "Best Tweedie power: 1.5 CV sMAPE: 0.9008\n",
            "OOF sMAPE (best power): 0.9008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 — Save OOF and run log\n",
        "\n",
        "oof_out = train[ID_COLS + [TARGET, \"y_pred_xgb_tweedie\"]].copy()\n",
        "oof_path = f\"{OOF_DIR}/xgb_tweedie_oof_{RUN_ID}_p{best_power}.parquet\"\n",
        "oof_out.to_parquet(oof_path, index=False)\n",
        "\n",
        "run_meta = {\n",
        "    \"run_id\": RUN_ID,\n",
        "    \"model\": \"xgb_tweedie\",\n",
        "    \"best_power\": float(best_power),\n",
        "    \"cv_smape_best\": float(cv_smape),\n",
        "    \"grid\": [\n",
        "        {\"power\": float(r[\"power\"]), \"cv_smape\": float(r[\"cv_smape\"]),\n",
        "         \"fold_smape\": [float(x) for x in r[\"fold_smape\"]]}\n",
        "        for r in results\n",
        "    ],\n",
        "    \"features\": FEATS,\n",
        "    \"params_base\": {k: (str(v) if k == \"device\" else v) for k, v in base_params.items()},\n",
        "}\n",
        "log_path = f\"{LOG_DIR}/{RUN_ID}.json\"\n",
        "with open(log_path, \"w\") as f:\n",
        "    json.dump(run_meta, f)\n",
        "\n",
        "print(\"Saved OOF:\", oof_path)\n",
        "print(\"Saved LOG:\", log_path)"
      ],
      "metadata": {
        "id": "Yo_QGBs8Owp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e87299-c1eb-42fd-db21-4276449fd634"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved OOF: /content/drive/MyDrive/ai4trade/predictions/oof/xgb_tweedie_oof_xgb_tweedie_h2_20251024_1438_p1.5.parquet\n",
            "Saved LOG: /content/drive/MyDrive/ai4trade/logs/runs/xgb_tweedie_h2_20251024_1438.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8 — Final fit on full train (best power) + forecast\n",
        "\n",
        "final_params = {**base_params, \"tweedie_variance_power\": best_power}\n",
        "final = XGBRegressor(**final_params)\n",
        "final.fit(\n",
        "    train[FEATS], train[TARGET],\n",
        "    # using train as eval set so early_stopping may NOT trigger; _predict_best handles both cases\n",
        "    eval_set=[(train[FEATS], train[TARGET])],\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "test[\"y_pred_xgb_tweedie\"] = _predict_best(final, test[FEATS]).clip(min=0).astype(np.float32)\n",
        "\n",
        "fcst_out = test[ID_COLS + [\"y_pred_xgb_tweedie\"]].copy()\n",
        "fcst_path = f\"{FCST_DIR}/xgb_tweedie_forecast_{RUN_ID}_p{best_power}.parquet\"\n",
        "fcst_out.to_parquet(fcst_path, index=False)\n",
        "\n",
        "print(\"Saved forecast:\", fcst_path)"
      ],
      "metadata": {
        "id": "WTv1fRYsO0oT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bdb2ab4-dfd0-4a15-c18e-05d77341e052"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved forecast: /content/drive/MyDrive/ai4trade/predictions/forecast/xgb_tweedie_forecast_xgb_tweedie_h2_20251024_1438_p1.5.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic distribution check\n",
        "print(\"Train target mean/std:\", train[TARGET].mean(), train[TARGET].std())\n",
        "print(\"OOF pred mean/std:\", train[\"y_pred_xgb_tweedie\"].mean(), train[\"y_pred_xgb_tweedie\"].std())\n",
        "\n",
        "# Sanity: non-negativity\n",
        "print(\"Any negative OOF preds?\", (train[\"y_pred_xgb_tweedie\"] < 0).any())\n",
        "print(\"Any negative FCST preds?\", (test[\"y_pred_xgb_tweedie\"] < 0).any())\n"
      ],
      "metadata": {
        "id": "Hav6JM0SPh5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea0b8ed-73f4-4f44-8106-e22c2f1af3fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train target mean/std: 2766904.697287732 43519207.314558625\n",
            "OOF pred mean/std: 2605624.0 24830836.0\n",
            "Any negative OOF preds? False\n",
            "Any negative FCST preds? False\n"
          ]
        }
      ]
    }
  ]
}